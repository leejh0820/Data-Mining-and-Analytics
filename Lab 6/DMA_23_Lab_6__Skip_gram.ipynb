{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDlU-kLCKDVZ"
      },
      "source": [
        "NAME = \"Jeonghyun Lee\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW9zL4V6KDVc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9a0ec075584699a44c46933457b0a8ba",
          "grade": false,
          "grade_id": "cell-a910b376742d04c0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ECD5r2hFKDVd"
      },
      "source": [
        "# Lab 6: Skip Gram\n",
        "\n",
        "**Please read the following instructions very carefully**\n",
        "\n",
        "## Working on the assignment / FAQs\n",
        "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments)\n",
        "- The type of question and the points they carry are indicated in each question cell\n",
        "- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n",
        "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
        "- You can delete the `raise NotImplementedError()`\n",
        "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n",
        "- That's about it. Happy coding!\n",
        "\n",
        "\n",
        "Available software:\n",
        " - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n",
        "\n",
        "_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a09a0bf3042da711c4bf843e9b4a4189",
          "grade": false,
          "grade_id": "cell-bf780e597c0216c8",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Vsocwry-KDVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0421f768-d522-4353-9caf-e5cf6f5918aa"
      },
      "source": [
        "!pip install gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load('word2vec-google-news-300') # this step might take ~10-15 minutes"
      ],
      "metadata": {
        "id": "TIcyAqlk6Qpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce283458-923c-4634-f5e1-847d9d372701"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "47031c66b74746d23ccc5e8369446a4b",
          "grade": false,
          "grade_id": "cell-3f89500615a0096f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZF74G9bDKDVh"
      },
      "source": [
        "### **Q1 (1 point)**\n",
        "Find the cosine similarity between the following word pairs\n",
        "\n",
        "- (France, England)\n",
        "- (come, go)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4d52dda406c3d8cd5e37d29755f0fb12",
          "grade": false,
          "grade_id": "cell-fbbe575f8f5a6368",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "SZD5ZaMvKDVk"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "similarity_pair1 = model.similarity('France', 'England')\n",
        "similarity_pair2 = model.similarity('come', 'go')\n",
        "similarity_pair3 = model.similarity('England', 'London')\n",
        "similarity_pair4 = model.similarity('France', 'Rocket')\n",
        "similarity_pair5 = model.similarity('big', 'bigger')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "569aa8b664a41d901bf7b0a5e23e9930",
          "grade": true,
          "grade_id": "cell-929d59ed5d67f618",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "tFUPLSK7KDVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fc54e4-c52d-4287-9447-5d1ef0f15f1d"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(similarity_pair1, similarity_pair2, similarity_pair3, similarity_pair4, similarity_pair5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.39804944 0.6604678 0.43992856 0.07114174 0.68423855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a7f270405ddf9ecbffde36e6c096b818",
          "grade": false,
          "grade_id": "cell-ccd6618b4fac3715",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZcqpWCjJKDVs"
      },
      "source": [
        "### **Q2 (1 point)**\n",
        "Write an expression to extract the vector representations of the words:\n",
        "\n",
        "- France\n",
        "- England\n",
        "- smaller\n",
        "- bigger\n",
        "- rocket\n",
        "- big\n",
        "\n",
        "Get only the first 5 elements for each vector representation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n",
        "vector_1 = model['France'][:5]\n",
        "vector_2 = model['England'][:5]\n",
        "vector_3 = model['smaller'][:5]\n",
        "vector_4 = model['bigger'][:5]\n",
        "vector_5 = model['rocket'][:5]\n",
        "vector_6 = model['big'][:5]"
      ],
      "metadata": {
        "id": "ElgK5QLuGi6S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "401940f859774b3c1ec48338fa15682e",
          "grade": true,
          "grade_id": "cell-6f34229370fa873f",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "Hkj2ROGTKDVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51dfd75-16f4-4394-94e5-cebbb40198d6"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(vector_1)\n",
        "print(vector_2)\n",
        "print(vector_3)\n",
        "print(vector_4)\n",
        "print(vector_5)\n",
        "print(vector_6)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n",
            "[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n",
            "[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n",
            "[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n",
            "[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n",
            "[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ac8b42811c924e7988f17b9dbd3f71ef",
          "grade": false,
          "grade_id": "cell-4ad44071d3785409",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "2UBnMwiXKDVy"
      },
      "source": [
        "### **Q3 (1 point)**\n",
        "Find the euclidean distances between the word pairs :\n",
        "\n",
        "- (France, England)\n",
        "- (smaller, bigger)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "eu_dist1 = np.linalg.norm(model['France'] - model['England'])\n",
        "eu_dist2 = np.linalg.norm(model['smaller'] - model['bigger'])\n",
        "eu_dist3 = np.linalg.norm(model['England'] - model['London'])\n",
        "eu_dist4 = np.linalg.norm(model['France'] - model['Rocket'])\n",
        "eu_dist5 = np.linalg.norm(model['big'] - model['bigger'])"
      ],
      "metadata": {
        "id": "JYUdXmCOMg45"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "17796eb5de342e8f8e841aa137a2c41c",
          "grade": true,
          "grade_id": "cell-15ffa50b82de21ad",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "HsSg0l2UKDV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d226e3ef-b1b1-44c9-b80e-390dfc367669"
      },
      "source": [
        "#This is an autograded cell, do not edit / delete\n",
        "print(eu_dist1)\n",
        "print(eu_dist2)\n",
        "print(eu_dist3)\n",
        "print(eu_dist4)\n",
        "print(eu_dist5)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0151067\n",
            "1.8618743\n",
            "2.8752837\n",
            "3.892071\n",
            "1.9586496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "afc0e843c7545e2df83448feda9f28f5",
          "grade": false,
          "grade_id": "cell-7cd8b9b67386376d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "XvO2iU7QKDWA"
      },
      "source": [
        "### **Q4 (1 point)**\n",
        "Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n",
        "- (King - Man + Queen)\n",
        "- (bigger - big + small)\n",
        "- (waiting - wait + run)\n",
        "- (Texas + Milwaukee â€“ Wisconsin)\n",
        "\n",
        "Note: If your kernel crashes due to low memory and restarts, reload the model from the top and try running this part again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "50ef096feb166865434fe2fca3d41f99",
          "grade": false,
          "grade_id": "cell-b72201968c5fd1ec",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "jCxWmA1eKDWB"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "closest1 = model.most_similar(positive=['King', 'Queen'], negative=['Man'],topn=2)\n",
        "closest2 = model.most_similar(positive=['bigger', 'small'], negative=['big'],topn=2)\n",
        "closest3 = model.most_similar(positive=['waiting', 'run'], negative=['wait'],topn=2)\n",
        "closest4 = model.most_similar(positive=['Texas', 'Milwaukee'], negative=['wisconsin'],topn=2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f9c5ff502264f29d2632c6387f92686a",
          "grade": true,
          "grade_id": "cell-b69718ab0e1470bc",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "io9elfD8KDWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcca2fd0-e630-46ae-b940-6b18d3b6d911"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(closest1)\n",
        "print(closest2)\n",
        "print(closest3)\n",
        "print(closest4)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Queen_Elizabeth', 0.5257916450500488), ('monarch', 0.5004087090492249)]\n",
            "[('larger', 0.7402471303939819), ('smaller', 0.7329993844032288)]\n",
            "[('running', 0.5654535889625549), ('runs', 0.49639999866485596)]\n",
            "[('Houston', 0.6948001384735107), ('San_Antonio', 0.6567700505256653)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "6432058d78f4fa52224c48a3b3e71d0d",
          "grade": false,
          "grade_id": "cell-73dca0e2072fef91",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "erUu4u71KDWJ"
      },
      "source": [
        "### **Q5 (3 points)**\n",
        "Using the vectors for the words in the Google News dataset, apply K-means clustering (K=2) and find the top 5 most representative words/phrases of each cluster.\n",
        "\n",
        "*Note: Since there are ~3Mil words in the vocabulary, you can downsample it to 25k randomly selected words*  \\\\\n",
        "*Hint: The \"similar_by_vector\" method might be useful*\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 0 with the code / value; Do not delete this cell\n",
        "# YOUR CODE HERE\n",
        "\n",
        "import random\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "sampling = random.choices(model.index_to_key, k = 25000)\n",
        "newData= pd.DataFrame([model[i] for i in sampling])\n",
        "newData['sampled_word'] = sampling\n",
        "X = newData.set_index('sampled_word')\n",
        "\n",
        "km = KMeans(n_clusters=2, random_state=42)\n",
        "\n",
        "km.fit(X)\n",
        "\n",
        "c1 = km.cluster_centers_[0]\n",
        "c2 = km.cluster_centers_[1]\n",
        "\n",
        "most_rep_cluster1 = model.similar_by_vector(c1)[:5]\n",
        "most_rep_cluster2 = model.similar_by_vector(c2)[:5]"
      ],
      "metadata": {
        "id": "iqTEPYr_YuRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb88f53a-142c-446b-cc98-93fc3ff6dca4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "7ecef46689f11d4d0a6fed72e049235f",
          "grade": true,
          "grade_id": "cell-80b177848b8b0212",
          "locked": false,
          "points": 3,
          "schema_version": 1,
          "solution": true
        },
        "id": "M3jN02fOKDWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e49e76-1a8b-4e6b-de8b-51cf61e26e44"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(most_rep_cluster1)\n",
        "print(most_rep_cluster2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Emil_Protalinski_Published', 0.9201331734657288), ('By_QianMian_####-##-##', 0.9180697202682495), ('BY_GEOFF_KOHL', 0.9167273640632629), ('By_HuDie_####-##-##', 0.91672682762146), ('By_XiaoBing_####-##-##', 0.9145992994308472)]\n",
            "[('http_dol##.net_index###.html_http', 0.9183775782585144), ('dol##.net_index####.html_http_dol##.net', 0.9085589051246643), ('index###.html_http_dol##.net_index###.html', 0.9074886441230774), ('Deltagen_undertakes', 0.9070373773574829), ('By_TRICIA_SCRUGGS', 0.903608500957489)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0467b27a0f59504cbb62b851a002386f",
          "grade": false,
          "grade_id": "cell-5b2a5e8ff6c74323",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "rmdtLoHkKDWR"
      },
      "source": [
        "### **Q6 (1 point)**\n",
        "What loss function does the skipgram model use and briefly describe what this function is minimizing.\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "774aef2c5bf8ef9d92e3489d1cd80390",
          "grade": true,
          "grade_id": "cell-90cc4b2c0ae8e2c2",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "SyOASYXOKDWS"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "#The Skip-gram model employs the Cross-Entropy loss function because it treats word embedding training as a classification problem. This loss function is used to minimize the error between predicted and actual word relationships. In essence, it works by maximizing the likelihood of correct word predictions while training the model. The Cross-Entropy loss is employed to update the model's weights during training, aiming to improve its ability to predict context words accurately.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c14f6069f64cc86ab6e384d28df270d8",
          "grade": false,
          "grade_id": "cell-74a177caaabb5009",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "dbpuJx9CKDWV"
      },
      "source": [
        "### **Bonus Question (1 point)**\n",
        "Find at least 2 interesting word vec combinations like the ones given in Q4\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "c2d42b5327f4b020c7e1706506dd5ce9",
          "grade": true,
          "grade_id": "cell-7351297993d72e83",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "pQM8C_T7KDWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1a2af4-78dd-4264-f6d0-032206cf72c4"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "interesting_word1 = model.most_similar(positive=['UC_Berkeley', 'UCLA'], negative = ['College'], topn=2)\n",
        "interesting_word2 = model.most_similar(positive=['engineering', 'computer'], negative = ['python'], topn=2)\n",
        "interesting_wrod3 = model.most_similar(positive=['UC_Berkeley', 'Stanford'], negative = ['College'], topn=2)\n",
        "print(interesting_word1)\n",
        "print(interesting_word2)\n",
        "print(interesting_wrod3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('UCSD', 0.6264442205429077), ('UCSB', 0.6223679184913635)]\n",
            "[('electrical_engineering', 0.528589129447937), ('engineer', 0.5098614692687988)]\n",
            "[('Berkeley', 0.6244730353355408), ('UCSD', 0.577602207660675)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULdYIXstC9ZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}